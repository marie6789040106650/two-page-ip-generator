// AIæ¨¡å‹é…ç½®
export interface AIModel {
  id: string
  name: string
  provider: 'siliconflow' | 'openai' | 'anthropic' | 'google'
  endpoint: string
  maxTokens: number
  temperature: number
  topP: number
  description: string
  category: 'chat' | 'image' | 'multimodal'
  streaming: boolean
  contextWindow: number
  pricing?: {
    input: number  // æ¯1K tokensä»·æ ¼
    output: number // æ¯1K tokensä»·æ ¼
  }
  features: string[]
  status: 'active' | 'deprecated' | 'beta'
}

// æ–‡æœ¬å¯¹è¯æ¨¡å‹é…ç½®
export const CHAT_MODELS: AIModel[] = [
  {
    id: 'deepseek-ai/DeepSeek-V3',
    name: 'DeepSeek-V3',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/chat/completions',
    maxTokens: 16000,
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸš€ æœ€æ¨è - æœ€æ–°çš„DeepSeek-V3æ¨¡å‹ï¼Œæ¨ç†èƒ½åŠ›å¼º',
    category: 'chat',
    streaming: true,
    contextWindow: 64000,
    pricing: { input: 0.14, output: 0.28 },
    features: ['æ¨ç†èƒ½åŠ›å¼º', 'ä¸­æ–‡ä¼˜åŒ–', 'ä»£ç ç”Ÿæˆ', 'æ•°å­¦è®¡ç®—'],
    status: 'active'
  },
  {
    id: 'moonshotai/Kimi-K2-Instruct',
    name: 'Kimi-K2 æ ‡å‡†ç‰ˆ',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/chat/completions',
    maxTokens: 8000,
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸ“š é•¿ä¸Šä¸‹æ–‡åœºæ™¯ - Moonshot Kimi-K2æ ‡å‡†ç‰ˆï¼Œé•¿ä¸Šä¸‹æ–‡æ”¯æŒ',
    category: 'chat',
    streaming: true,
    contextWindow: 200000,
    pricing: { input: 0.5, output: 1.0 },
    features: ['è¶…é•¿ä¸Šä¸‹æ–‡', 'æ–‡æ¡£åˆ†æ', 'å¤šè½®å¯¹è¯', 'ä¸­æ–‡ä¼˜åŒ–'],
    status: 'active'
  },
  {
    id: 'Pro/moonshotai/Kimi-K2-Instruct',
    name: 'Kimi-K2 Proç‰ˆ',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/chat/completions',
    maxTokens: 16000,
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸ¯ é«˜è¦æ±‚åœºæ™¯ - Moonshot Kimi-K2ä¸“ä¸šç‰ˆï¼Œæ›´å¼ºæ€§èƒ½å’Œæ›´é•¿ä¸Šä¸‹æ–‡',
    category: 'chat',
    streaming: true,
    contextWindow: 200000,
    pricing: { input: 1.0, output: 2.0 },
    features: ['è¶…é•¿ä¸Šä¸‹æ–‡', 'é«˜æ€§èƒ½', 'ä¸“ä¸šåˆ†æ', 'å¤æ‚æ¨ç†'],
    status: 'active'
  },
  {
    id: 'THUDM/GLM-4.1V-9B-Thinking',
    name: 'GLM-4.1V-9B-Thinking',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/chat/completions',
    maxTokens: 8000,
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸ§  æ€ç»´é“¾æ¨ç† - æ¸…åGLM-4.1Væ€ç»´æ¨¡å‹ï¼Œæ”¯æŒå¤æ‚æ¨ç†',
    category: 'chat',
    streaming: true,
    contextWindow: 32000,
    pricing: { input: 0.5, output: 1.0 },
    features: ['æ€ç»´é“¾æ¨ç†', 'é€»è¾‘åˆ†æ', 'å¤šæ¨¡æ€', 'ä¸­æ–‡ä¼˜åŒ–'],
    status: 'active'
  },
  {
    id: 'deepseek-ai/DeepSeek-R1-0528-Qwen3-8B',
    name: 'DeepSeek-R1-Qwen3-8B',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/chat/completions',
    maxTokens: 8000,
    temperature: 0.7,
    topP: 0.9,
    description: 'âš¡ æ¨ç†ä¼˜åŒ– - DeepSeek-R1æ¨ç†æ¨¡å‹ï¼ŒåŸºäºQwen3ä¼˜åŒ–',
    category: 'chat',
    streaming: true,
    contextWindow: 32000,
    pricing: { input: 0.2, output: 0.4 },
    features: ['æ¨ç†ä¼˜åŒ–', 'å¿«é€Ÿå“åº”', 'ä¸­æ–‡æ”¯æŒ', 'ä»£ç ç†è§£'],
    status: 'active'
  },
  {
    id: 'Qwen/Qwen2.5-72B-Instruct',
    name: 'Qwen2.5-72B',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/chat/completions',
    maxTokens: 8000,
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸ¯ é€šä¹‰åƒé—® - é˜¿é‡Œäº‘å¤§æ¨¡å‹ï¼Œç»¼åˆèƒ½åŠ›å¼º',
    category: 'chat',
    streaming: true,
    contextWindow: 32000,
    pricing: { input: 0.5, output: 1.0 },
    features: ['ç»¼åˆèƒ½åŠ›å¼º', 'ä¸­æ–‡ä¼˜åŒ–', 'å¤šé¢†åŸŸçŸ¥è¯†', 'ç¨³å®šæ€§å¥½'],
    status: 'active'
  },
  // OpenAI æ¨¡å‹
  {
    id: 'gpt-4',
    name: 'GPT-4',
    provider: 'openai',
    endpoint: 'https://api.openai.com/v1/chat/completions',
    maxTokens: 4000,
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸŒŸ OpenAI GPT-4 - ä¸šç•Œæ ‡æ†æ¨¡å‹',
    category: 'chat',
    streaming: true,
    contextWindow: 8000,
    pricing: { input: 30, output: 60 },
    features: ['ä¸šç•Œæ ‡æ†', 'å¤šè¯­è¨€æ”¯æŒ', 'æ¨ç†èƒ½åŠ›å¼º', 'åˆ›æ„å†™ä½œ'],
    status: 'active'
  },
  {
    id: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'openai',
    endpoint: 'https://api.openai.com/v1/chat/completions',
    maxTokens: 4000,
    temperature: 0.7,
    topP: 0.9,
    description: 'âš¡ OpenAI GPT-3.5 - å¿«é€Ÿå“åº”ï¼Œæˆæœ¬è¾ƒä½',
    category: 'chat',
    streaming: true,
    contextWindow: 4000,
    pricing: { input: 1.5, output: 2.0 },
    features: ['å¿«é€Ÿå“åº”', 'æˆæœ¬è¾ƒä½', 'å¤šè¯­è¨€æ”¯æŒ', 'å¯¹è¯ä¼˜åŒ–'],
    status: 'active'
  },
  // Google Gemini æ¨¡å‹
  {
    id: 'gemini-1.5-pro',
    name: 'Gemini 1.5 Pro',
    provider: 'google',
    endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent',
    maxTokens: 8000,
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸ§  Google Gemini 1.5 Pro - å¤šæ¨¡æ€èƒ½åŠ›å¼ºï¼Œè¶…é•¿ä¸Šä¸‹æ–‡',
    category: 'multimodal',
    streaming: true,
    contextWindow: 2000000,
    pricing: { input: 1.25, output: 5.0 },
    features: ['è¶…é•¿ä¸Šä¸‹æ–‡', 'å¤šæ¨¡æ€æ”¯æŒ', 'ä»£ç ç”Ÿæˆ', 'æ•°å­¦æ¨ç†', 'æ–‡æ¡£åˆ†æ'],
    status: 'active'
  },
  {
    id: 'gemini-1.5-flash',
    name: 'Gemini 1.5 Flash',
    provider: 'google',
    endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent',
    maxTokens: 8000,
    temperature: 0.7,
    topP: 0.9,
    description: 'âš¡ Google Gemini 1.5 Flash - å¿«é€Ÿå“åº”ï¼Œæˆæœ¬æ›´ä½',
    category: 'multimodal',
    streaming: true,
    contextWindow: 1000000,
    pricing: { input: 0.075, output: 0.3 },
    features: ['å¿«é€Ÿå“åº”', 'æˆæœ¬è¾ƒä½', 'å¤šæ¨¡æ€æ”¯æŒ', 'å®æ—¶å¤„ç†'],
    status: 'active'
  },
  {
    id: 'gemini-2.0-flash-exp',
    name: 'Gemini 2.0 Flash (å®éªŒç‰ˆ)',
    provider: 'google',
    endpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent',
    maxTokens: 12000, // æå‡è¾“å‡ºé•¿åº¦ï¼Œé€‚åˆé•¿å†…å®¹ç”Ÿæˆ
    temperature: 0.7,
    topP: 0.9,
    description: 'ğŸš€ Google Gemini 2.0 Flash - æœ€æ–°å®éªŒç‰ˆæœ¬ï¼Œæ”¯æŒé•¿å†…å®¹ç”Ÿæˆ',
    category: 'multimodal',
    streaming: true,
    contextWindow: 1000000,
    pricing: { input: 0.075, output: 0.3 }, // ä¸Flashç›¸åŒçš„å®šä»·
    features: ['æœ€æ–°æŠ€æœ¯', 'å¤šæ¨¡æ€æ”¯æŒ', 'é•¿å†…å®¹ç”Ÿæˆ', 'å›¾åƒç†è§£', 'æ€§èƒ½ä¼˜åŒ–'],
    status: 'beta'
  }
]

// å›¾ç‰‡ç”Ÿæˆæ¨¡å‹é…ç½®
export const IMAGE_MODELS: AIModel[] = [
  {
    id: 'black-forest-labs/FLUX.1-schnell',
    name: 'FLUX.1-schnell',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/images/generations',
    maxTokens: 0,
    temperature: 0,
    topP: 0,
    description: 'âš¡ FLUX.1å¿«é€Ÿç‰ˆæœ¬ï¼Œç”Ÿæˆé€Ÿåº¦å¿«',
    category: 'image',
    streaming: false,
    contextWindow: 0,
    pricing: { input: 0.05, output: 0 },
    features: ['ç”Ÿæˆé€Ÿåº¦å¿«', 'è´¨é‡è‰¯å¥½', 'å¤šæ ·åŒ–é£æ ¼', 'å•†ç”¨å‹å¥½'],
    status: 'active'
  },
  {
    id: 'black-forest-labs/FLUX.1-dev',
    name: 'FLUX.1-dev',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/images/generations',
    maxTokens: 0,
    temperature: 0,
    topP: 0,
    description: 'ğŸ¨ FLUX.1å¼€å‘ç‰ˆæœ¬ï¼Œè´¨é‡æ›´é«˜',
    category: 'image',
    streaming: false,
    contextWindow: 0,
    pricing: { input: 0.1, output: 0 },
    features: ['é«˜è´¨é‡è¾“å‡º', 'ç»†èŠ‚ä¸°å¯Œ', 'è‰ºæœ¯é£æ ¼', 'ä¸“ä¸šçº§åˆ«'],
    status: 'active'
  },
  {
    id: 'stabilityai/stable-diffusion-3-5-large',
    name: 'Stable Diffusion 3.5',
    provider: 'siliconflow',
    endpoint: 'https://api.siliconflow.cn/v1/images/generations',
    maxTokens: 0,
    temperature: 0,
    topP: 0,
    description: 'ğŸ–¼ï¸ Stable Diffusion 3.5å¤§æ¨¡å‹',
    category: 'image',
    streaming: false,
    contextWindow: 0,
    pricing: { input: 0.08, output: 0 },
    features: ['å¼€æºæ¨¡å‹', 'å¯æ§æ€§å¼º', 'ç¤¾åŒºæ”¯æŒ', 'å¤šç§å°ºå¯¸'],
    status: 'active'
  }
]

// é»˜è®¤æ¨¡å‹é…ç½® - ä¼˜å…ˆä½¿ç”¨æœ‰å¯†é’¥çš„æœåŠ¡
export const DEFAULT_CHAT_MODEL = CHAT_MODELS[0] // DeepSeek-V3 (SiliconFlow)
export const DEFAULT_IMAGE_MODEL = IMAGE_MODELS[0] // FLUX.1-schnell (SiliconFlow)

// å¤‡ç”¨æ¨¡å‹é…ç½® - åŸºäºå¯ç”¨å¯†é’¥çš„æ™ºèƒ½é€‰æ‹©
export const FALLBACK_MODELS = {
  // å¿«é€Ÿå“åº”åœºæ™¯ - ä¼˜å…ˆä½¿ç”¨Gemini Flash (æœ€ä¾¿å®œ)
  FAST_RESPONSE: CHAT_MODELS.find(m => m.id === 'gemini-1.5-flash') || DEFAULT_CHAT_MODEL,

  // é•¿ä¸Šä¸‹æ–‡åœºæ™¯ - ä½¿ç”¨Gemini Pro (200ä¸‡tokens)
  LONG_CONTEXT: CHAT_MODELS.find(m => m.id === 'gemini-1.5-pro') || DEFAULT_CHAT_MODEL,

  // å¤šæ¨¡æ€åœºæ™¯ - ä½¿ç”¨Gemini Pro
  MULTIMODAL: CHAT_MODELS.find(m => m.id === 'gemini-1.5-pro') || DEFAULT_CHAT_MODEL,

  // å®éªŒæ€§åœºæ™¯ - ä½¿ç”¨Gemini 2.0 (å…è´¹)
  EXPERIMENTAL: CHAT_MODELS.find(m => m.id === 'gemini-2.0-flash-exp') || DEFAULT_CHAT_MODEL,

  // é¢„ç®—ä¼˜å…ˆ - ä½¿ç”¨å…è´¹çš„Gemini 2.0æˆ–æœ€ä¾¿å®œçš„Flash
  BUDGET: CHAT_MODELS.find(m => m.id === 'gemini-2.0-flash-exp') ||
    CHAT_MODELS.find(m => m.id === 'gemini-1.5-flash') ||
    DEFAULT_CHAT_MODEL
}

// æ ¹æ®IDè·å–æ¨¡å‹é…ç½®
export function getModelById(modelId: string): AIModel | undefined {
  return [...CHAT_MODELS, ...IMAGE_MODELS].find(model => model.id === modelId)
}

// è·å–æŒ‡å®šç±»åˆ«çš„æ¨¡å‹
export function getModelsByCategory(category: 'chat' | 'image' | 'multimodal'): AIModel[] {
  return [...CHAT_MODELS, ...IMAGE_MODELS].filter(model => model.category === category)
}

// è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹
export function getModelsByProvider(provider: 'siliconflow' | 'openai' | 'anthropic' | 'google'): AIModel[] {
  return [...CHAT_MODELS, ...IMAGE_MODELS].filter(model => model.provider === provider)
}

// è·å–æ”¯æŒæµå¼å“åº”çš„æ¨¡å‹
export function getStreamingModels(): AIModel[] {
  return [...CHAT_MODELS, ...IMAGE_MODELS].filter(model => model.streaming)
}

// è·å–æ´»è·ƒçŠ¶æ€çš„æ¨¡å‹
export function getActiveModels(): AIModel[] {
  return [...CHAT_MODELS, ...IMAGE_MODELS].filter(model => model.status === 'active')
}

// æ ¹æ®ä»·æ ¼æ’åºæ¨¡å‹ï¼ˆä»ä½åˆ°é«˜ï¼‰
export function getModelsByPrice(category?: 'chat' | 'image' | 'multimodal'): AIModel[] {
  let models = category ? getModelsByCategory(category) : [...CHAT_MODELS, ...IMAGE_MODELS];
  return models.sort((a, b) => {
    const priceA = a.pricing ? a.pricing.input + a.pricing.output : 0;
    const priceB = b.pricing ? b.pricing.input + b.pricing.output : 0;
    return priceA - priceB;
  });
}

// æ ¹æ®ä¸Šä¸‹æ–‡çª—å£å¤§å°æ’åºæ¨¡å‹ï¼ˆä»å¤§åˆ°å°ï¼‰
export function getModelsByContextWindow(): AIModel[] {
  return [...CHAT_MODELS].sort((a, b) => b.contextWindow - a.contextWindow);
}

// è·å–æ¨èçš„æ¨¡å‹é…ç½® - åŸºäºä½ çš„å¯ç”¨å¯†é’¥ä¼˜åŒ–
export function getRecommendedModels(): {
  chat: AIModel;
  image: AIModel;
  budget: AIModel;
  performance: AIModel;
  multimodal: AIModel;
  longContext: AIModel;
  longGeneration: AIModel; // æ–°å¢ï¼šé•¿å†…å®¹ç”Ÿæˆä¸“ç”¨
} {
  return {
    chat: DEFAULT_CHAT_MODEL, // DeepSeek-V3 (SiliconFlow) - æ—¥å¸¸å¯¹è¯
    image: DEFAULT_IMAGE_MODEL, // FLUX.1-schnell (SiliconFlow) - å›¾ç‰‡ç”Ÿæˆ
    budget: CHAT_MODELS.find(m => m.id === 'gemini-2.0-flash-exp') ||
      CHAT_MODELS.find(m => m.id === 'gemini-1.5-flash') ||
      DEFAULT_CHAT_MODEL, // å…è´¹Gemini 2.0 > Gemini Flash > DeepSeek
    performance: CHAT_MODELS.find(m => m.id === 'gemini-1.5-pro') ||
      CHAT_MODELS.find(m => m.id === 'Pro/moonshotai/Kimi-K2-Instruct') ||
      DEFAULT_CHAT_MODEL, // Gemini Pro > Kimi Pro > DeepSeek
    multimodal: CHAT_MODELS.find(m => m.id === 'gemini-1.5-pro') || DEFAULT_CHAT_MODEL, // Gemini Proæœ€ä½³
    longContext: CHAT_MODELS.find(m => m.id === 'gemini-1.5-pro') || DEFAULT_CHAT_MODEL, // Gemini Pro (200ä¸‡tokens)
    longGeneration: CHAT_MODELS.find(m => m.id === 'gemini-1.5-pro') ||
      CHAT_MODELS.find(m => m.id === 'moonshotai/Kimi-K2-Instruct') ||
      DEFAULT_CHAT_MODEL // é•¿å†…å®¹ç”Ÿæˆï¼šGemini Pro > Kimi > DeepSeek
  };
}

// éªŒè¯æ¨¡å‹é…ç½®
export function validateModelConfig(modelId: string, provider: string): boolean {
  const model = getModelById(modelId);
  return model !== undefined && model.provider === provider && model.status === 'active';
}

// è·å–æ¨¡å‹çš„APIå¯†é’¥ç¯å¢ƒå˜é‡å
export function getModelApiKeyEnvName(provider: string): string {
  switch (provider) {
    case 'siliconflow':
      return 'SILICONFLOW_API_KEY';
    case 'openai':
      return 'OPENAI_API_KEY';
    case 'anthropic':
      return 'ANTHROPIC_API_KEY';
    case 'google':
      return 'GOOGLE_API_KEY';
    default:
      return 'API_KEY';
  }
}

// è·å–APIå¯†é’¥ï¼ˆä¼˜å…ˆä»é…ç½®ç®¡ç†å™¨ï¼‰
export function getApiKey(provider: string): string | null {
  // åœ¨å®¢æˆ·ç«¯ç¯å¢ƒä¸‹ï¼Œç›´æ¥è¿”å› nullï¼ŒAPI å¯†é’¥åªåœ¨æœåŠ¡ç«¯ä½¿ç”¨
  if (typeof window !== 'undefined') {
    return null;
  }
  
  // æœåŠ¡ç«¯ç¯å¢ƒä¸‹ï¼Œå°è¯•ä»é…ç½®ç®¡ç†å™¨è·å–
  try {
    // åŠ¨æ€å¯¼å…¥é…ç½®ç®¡ç†å™¨ä»¥é¿å…å¾ªç¯ä¾èµ–
    // ä½¿ç”¨ eval æ¥é¿å… webpack é™æ€åˆ†æ
    const configManager = eval('require')('@/lib/config-manager');
    return configManager.getApiKey(provider);
  } catch (error) {
    // é™çº§åˆ°ç¯å¢ƒå˜é‡
    const envName = getModelApiKeyEnvName(provider);
    return process.env[envName] || null;
  }
}

// ä¼°ç®—tokenæˆæœ¬
export function estimateTokenCost(model: AIModel, inputTokens: number, outputTokens: number): number {
  if (!model.pricing) return 0;
  return (inputTokens / 1000) * model.pricing.input + (outputTokens / 1000) * model.pricing.output;
}

// æ¨¡å‹èƒ½åŠ›æ£€æŸ¥
export function hasFeature(model: AIModel, feature: string): boolean {
  return model.features.includes(feature);
}

// æ™ºèƒ½æ¨¡å‹é€‰æ‹© - åŸºäºä»»åŠ¡ç±»å‹å’Œå¯ç”¨å¯†é’¥
export function selectOptimalModel(taskType: 'fast' | 'long_context' | 'multimodal' | 'budget' | 'experimental' | 'long_generation' | 'default'): AIModel {
  // æ£€æŸ¥å¯ç”¨çš„APIå¯†é’¥ï¼ˆä¼˜å…ˆä»é…ç½®ç®¡ç†å™¨ï¼‰
  const availableKeys = {
    siliconflow: !!getApiKey('siliconflow'),
    google: !!getApiKey('google'),
    openai: !!getApiKey('openai'),
    anthropic: !!getApiKey('anthropic')
  };

  switch (taskType) {
    case 'fast':
      // å¿«é€Ÿå“åº”ï¼šä¼˜å…ˆGemini Flashï¼Œå¤‡é€‰DeepSeek
      if (availableKeys.google) {
        return FALLBACK_MODELS.FAST_RESPONSE;
      }
      return availableKeys.siliconflow ? DEFAULT_CHAT_MODEL : CHAT_MODELS.find(m => m.provider === 'openai') || DEFAULT_CHAT_MODEL;

    case 'long_context':
      // é•¿ä¸Šä¸‹æ–‡ï¼šä¼˜å…ˆGemini Proï¼Œå¤‡é€‰Kimi
      if (availableKeys.google) {
        return FALLBACK_MODELS.LONG_CONTEXT;
      }
      return availableKeys.siliconflow ?
        CHAT_MODELS.find(m => m.id === 'moonshotai/Kimi-K2-Instruct') || DEFAULT_CHAT_MODEL :
        DEFAULT_CHAT_MODEL;

    case 'multimodal':
      // å¤šæ¨¡æ€ï¼šä¼˜å…ˆGemini Pro
      if (availableKeys.google) {
        return FALLBACK_MODELS.MULTIMODAL;
      }
      return DEFAULT_CHAT_MODEL;

    case 'budget':
      // é¢„ç®—ä¼˜å…ˆï¼šå…è´¹Gemini 2.0 > Gemini Flash > DeepSeek
      if (availableKeys.google) {
        return FALLBACK_MODELS.BUDGET;
      }
      return availableKeys.siliconflow ?
        CHAT_MODELS.find(m => m.id === 'deepseek-ai/DeepSeek-R1-0528-Qwen3-8B') || DEFAULT_CHAT_MODEL :
        DEFAULT_CHAT_MODEL;

    case 'experimental':
      // å®éªŒæ€§ï¼šä¼˜å…ˆå…è´¹çš„Gemini 2.0
      if (availableKeys.google) {
        return FALLBACK_MODELS.EXPERIMENTAL;
      }
      return DEFAULT_CHAT_MODEL;

    case 'long_generation':
      // é•¿å†…å®¹ç”Ÿæˆï¼šä¼˜å…ˆå…è´¹çš„Gemini 2.0ï¼Œå¤‡é€‰Gemini Proï¼Œå†å¤‡é€‰Kimi
      if (availableKeys.google) {
        // é¦–é€‰ï¼šå…è´¹çš„Gemini 2.0 (12K tokensè¾“å‡ºï¼Œå®Œå…¨å…è´¹!)
        const gemini2 = CHAT_MODELS.find(m => m.id === 'gemini-2.0-flash-exp');
        if (gemini2) return gemini2;

        // å¤‡é€‰ï¼šç¨³å®šçš„Gemini Pro
        return CHAT_MODELS.find(m => m.id === 'gemini-1.5-pro') || DEFAULT_CHAT_MODEL;
      }
      return availableKeys.siliconflow ?
        CHAT_MODELS.find(m => m.id === 'moonshotai/Kimi-K2-Instruct') || DEFAULT_CHAT_MODEL :
        DEFAULT_CHAT_MODEL;

    default:
      // é»˜è®¤ï¼šä½¿ç”¨ä¸»åŠ›æ¨¡å‹
      return availableKeys.siliconflow ? DEFAULT_CHAT_MODEL :
        availableKeys.google ? FALLBACK_MODELS.FAST_RESPONSE :
          DEFAULT_CHAT_MODEL;
  }
}

// æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯å ä½ç¬¦ï¼‰
function isValidApiKey(key: string | null): boolean {
  if (!key) return false;
  
  // æ£€æŸ¥æ˜¯å¦æ˜¯å ä½ç¬¦
  const placeholders = [
    'your_openai_key_here',
    'your_anthropic_key_here',
    'your_google_key_here',
    'your_siliconflow_key_here',
    'sk-placeholder',
    'placeholder'
  ];
  
  return !placeholders.includes(key.toLowerCase()) && key.length > 10;
}

// ç¨³å®šçš„æ¨¡å‹ä¼˜å…ˆçº§é…ç½® - åŸºäºä½ çš„å®é™…APIå¯†é’¥
export function getStableModelPriority(): AIModel[] {
  // ä½ çš„å¯ç”¨APIå¯†é’¥ï¼šSiliconFlow + Google
  const stablePriorityList = [
    // ç¬¬1ä¼˜å…ˆçº§ï¼šå…è´¹ä¸”ç¨³å®šçš„æ¨¡å‹
    'gemini-2.0-flash-exp',           // Google Gemini 2.0 - å®Œå…¨å…è´¹ï¼Œ12Kè¾“å‡º
    
    // ç¬¬2ä¼˜å…ˆçº§ï¼šæ€§ä»·æ¯”æœ€é«˜çš„ä»˜è´¹æ¨¡å‹  
    'deepseek-ai/DeepSeek-V3',        // SiliconFlow DeepSeek-V3 - ä¾¿å®œä¸”å¼ºå¤§
    'gemini-1.5-flash',               // Google Gemini Flash - å¿«é€Ÿä¾¿å®œ
    
    // ç¬¬3ä¼˜å…ˆçº§ï¼šé«˜æ€§èƒ½æ¨¡å‹
    'gemini-1.5-pro',                 // Google Gemini Pro - æœ€å¼ºå¤šæ¨¡æ€
    'moonshotai/Kimi-K2-Instruct',    // SiliconFlow Kimi - é•¿ä¸Šä¸‹æ–‡
    
    // ç¬¬4ä¼˜å…ˆçº§ï¼šå…¶ä»–å¯ç”¨æ¨¡å‹
    'Qwen/Qwen2.5-72B-Instruct',     // SiliconFlow Qwen
    'deepseek-ai/DeepSeek-R1-0528-Qwen3-8B' // SiliconFlow DeepSeek-R1
  ];

  return stablePriorityList
    .map(id => CHAT_MODELS.find(m => m.id === id))
    .filter((model): model is AIModel => model !== undefined);
}

// è·å–å½“å‰å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ˆç¨³å®šç‰ˆæœ¬ï¼‰
export function getAvailableModels(): AIModel[] {
  // ç›´æ¥è¿”å›ç¨³å®šçš„ä¼˜å…ˆçº§åˆ—è¡¨ï¼Œé¿å…å®æ—¶æ£€æŸ¥çš„ä¸ç¨³å®šæ€§
  return getStableModelPriority();
}

// è·å–å¯ç”¨çš„èŠå¤©æ¨¡å‹ï¼ˆç¨³å®šç‰ˆæœ¬ï¼‰
export function getAvailableChatModels(): AIModel[] {
  return getStableModelPriority(); // ç›´æ¥è¿”å›ç¨³å®šçš„ä¼˜å…ˆçº§åˆ—è¡¨
}

// è·å–é»˜è®¤æ¨èæ¨¡å‹ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
export function getDefaultRecommendedModel(): AIModel {
  const stableModels = getStableModelPriority();
  return stableModels[0] || DEFAULT_CHAT_MODEL; // è¿”å›ç¬¬ä¸€ä¼˜å…ˆçº§æ¨¡å‹
}

// è·å–æŒ‰åœºæ™¯åˆ†ç±»çš„æ¨èæ¨¡å‹
export function getScenarioModels(): {
  free: AIModel;           // å…è´¹ä½¿ç”¨
  fast: AIModel;           // å¿«é€Ÿå“åº”  
  quality: AIModel;        // é«˜è´¨é‡è¾“å‡º
  longContext: AIModel;    // é•¿ä¸Šä¸‹æ–‡
  multimodal: AIModel;     // å¤šæ¨¡æ€
  budget: AIModel;         // é¢„ç®—ä¼˜å…ˆ
} {
  const models = getStableModelPriority();
  
  return {
    free: models.find(m => m.id === 'gemini-2.0-flash-exp') || models[0],
    fast: models.find(m => m.id === 'gemini-1.5-flash') || models[1], 
    quality: models.find(m => m.id === 'deepseek-ai/DeepSeek-V3') || models[1],
    longContext: models.find(m => m.id === 'gemini-1.5-pro') || models[3],
    multimodal: models.find(m => m.id === 'gemini-1.5-pro') || models[3],
    budget: models.find(m => m.id === 'gemini-2.0-flash-exp') || models[0]
  };
}

// è·å–æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯
export function getModelStats(): {
  total: number;
  byCategory: Record<string, number>;
  byProvider: Record<string, number>;
  byStatus: Record<string, number>;
} {
  const allModels = [...CHAT_MODELS, ...IMAGE_MODELS];

  return {
    total: allModels.length,
    byCategory: {
      chat: CHAT_MODELS.length,
      image: IMAGE_MODELS.length,
      multimodal: allModels.filter(m => m.category === 'multimodal').length
    },
    byProvider: {
      siliconflow: allModels.filter(m => m.provider === 'siliconflow').length,
      openai: allModels.filter(m => m.provider === 'openai').length,
      anthropic: allModels.filter(m => m.provider === 'anthropic').length,
      google: allModels.filter(m => m.provider === 'google').length
    },
    byStatus: {
      active: allModels.filter(m => m.status === 'active').length,
      deprecated: allModels.filter(m => m.status === 'deprecated').length,
      beta: allModels.filter(m => m.status === 'beta').length
    }
  };
}